{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 1: Hello World\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a guide for the Machine Learning Recipes with Josh Gordon available on [YouTube](https://www.youtube.com/playlist?list=PLOU2XLYxmsIIuiBfYad6rFYQU_jL2ryal)\n",
    "\n",
    "\n",
    "We have covered the installation of the anaconda in Week 0. We also wrote the first machine learning code [hello_world.py](scripts/hello_world.py). One realization is that this course expect you to have the basic experience with python. I think the instructor has chosen python because of how easier it is to learn, its clear synthax and its growing audience expecially in the data science community. You will be surprise to learn how many financial analysts are using python !! If you are not yet comfortable with python, I recommend you reviews Chris Albon's short [tutorials](http://chrisalbon.com/#Python) again.\n",
    "\n",
    "The first step we did in the hello world is to import the tree object from the scikit learn\n",
    "```python\n",
    "from sklearn import tree\n",
    "```\n",
    "The next step was to prepare the data. Each observation is a list of value of each of the features. For the case we had only the weight and texture. He called `features` the list of all the observations (which is a nexted list). Notice that all the elements of this list is a list of exactly two elements, weight and texture. The labels are in the same order as their corresponding explanatory variables. \n",
    "```python\n",
    "features = [[140, 1], [130, 1], [150, 0], [170, 0]] # Bumpy = 0, Smooth = 1\n",
    "labels = [0, 0, 1, 1] # Apple = 0, Orange = 1\n",
    "```\n",
    "The thirst step was to create and instance of decision tree from the tree object. \n",
    "```python\n",
    "clf = tree.DecisionTreeClassifier()\n",
    "```\n",
    "Then fit the data\n",
    "```python\n",
    "clf = clf.fit(features, labels)\n",
    "```\n",
    "This method prect the label for a fruit of 160 gram and bumpy texture. The prediction was an orange !!\n",
    "```python\n",
    "expected_label = clf.predict([[160, 0]])\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The instructor explains that this program is intended to **classify** a piece of fruit. We can then say that it is a classification program. Classification is one of the many machine learning algorithms that are used to classify objects from others. Classification is in the category of learning algorithms called **supervised**. In this category there is a response variable for each observation of features (target variables are ofter referred to as labels or classes). For the fruit example, for a given weight and texture of the fruit, there is an associated target variables. JB points out that during supervised learning the classify is trained then used to make the predict future observations. To train the algorithm we feed the *training data* to the algorithm. The traininng data set is made of a list of feature vectors and a list of labels. \n",
    "![test](http://api.ning.com/files/-ByhuHJ6vtKmMhYH1DvoD5L2g5KxyMI4xifmn4lNOAssyWwJg9LS4*aLzWMHmmSKu3pWI5dJjBzhnmcrhJEUeEvaTT-3x07J/01_supervised_learning.png)\n",
    "After the algorithm has been trained, we feed it with the testing data set. The image above explain the process of supervised learning [credit: Kaggle.com]. \n",
    "In order to evaluate the learning of the machine, we compute the level of accuracy or knowledge representation.\n",
    "Other supervised learning algorithms include regression, naive Bayes, support vector machines, decisions trees\n",
    ", ...\n",
    "\n",
    "We can summary the machine learning application process into the folling steps and each of the steps requires some sort of computer programming: \n",
    "\n",
    "1. Collect the data\n",
    "2. Prepare the data to match the format accepted by the classifier\n",
    "3. Analyze the data and split the data into training and testing set\n",
    "4. Train the classifier using the training data set\n",
    "5. Test the classifier and evaluate its level of accuracy. \n",
    "6. Use the classifier. \n",
    "\n",
    "### Question:\n",
    "1. Can you think of the reason that the data has to be split into training and testing sets ? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\n"
     ]
    }
   ],
   "source": [
    "from sklearn import tree\n",
    "features = [[140, 1], [130, 1], [150, 0], [170, 0]] # Bumpy = 0, Smooth = 1\n",
    "labels = [0, 0, 1, 1] # Apple = 0, Orange = 1\n",
    "clf = tree.DecisionTreeClassifier()\n",
    "clf = clf.fit(features, labels)\n",
    "print (clf.predict([[160, 0]])) #It should print [1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading \n",
    "1. Read chapter 2 of [ESL](http://statweb.stanford.edu/~tibs/ElemStatLearn/)\n",
    "2. Take a look at this [ressource](http://blog.kaggle.com/2015/04/22/scikit-learn-video-3-machine-learning-first-steps-with-the-iris-dataset/)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
